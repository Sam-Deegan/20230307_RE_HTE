---
title: "Replication_Group_1"
short: "A shorter title"
journal: "AER" # AER, AEJ, PP, JEL
month: "`r format(Sys.Date(), '%m')`"
year: "`r format(Sys.Date(), '%Y')`"
vol: 1
issue: 1
jel:
  - A10
  - A11
keywords:
  - first keyword
  - second keyword
author:
  - name: Alice Anonymous
    firstname: Alice
    surname: Anonymous
    email: alice@example.com
    affiliation: Some Institute of Technology
  - name: Bob Security
    firstname: Bob
    surname: Security
    email: bob@example.com
    affiliation: Another University
acknowledgements: |
  Acknowledgements
abstract: |
  Abstract goes here
output:  rticles::aea_article
---

\section{Introduction}


\begin{itemize}

\item  Briefly explain the original study and its contribution to the literature

\item  Discuss the importance of replication in economics research and the goals of the replication paper

\end{itemize}

In this paper, we replicate "Liquidity Constraints, Informal Institutions, and the Adoption of Weather Insurance" by Belissa et al. (2019) and extend it to account for heterogeneous treatment effects via a Multi-Arm-Causal-Forest model. 
The original study finds that drought insurance uptake among smallholder farmers in Ethiopia could be higher, as smallholders suffer from seasonal liquidity constraints associated with harvest periods. The paper builds upon previous work in the literature, which finds that downside production risks impede farm modernisation (Emerick et al., 2016). By introducing a novel insurance product which delays repayment (IOUs) until after the harvest, the authors find that insurance uptake can be considerably increased. 
The authors conducted a Randomised Control Trial (RCT) in 2015 using a pre-existing index-based drought-insurance product offered by Oromia Insurance Company (OIC) in the Ethiopia Rift Valley area. The product is typically sold during the rainy season before the harvest, and payouts are determined based on local rainfall levels.
To improve the effectiveness and uptake of the insurance product, the authors made three modifications to the original product. Firstly, they allowed deferred IOU payment post-harvest to alleviate smallholder liquidity constraints. Secondly, they varied the market channel and advertised the product through local (Iddir) leaders to increase trust and information. Finally, they imposed harsher contract terms to reduce the likelihood of default. In total, six different index-based insurance contracts were offered. The availability of these modified insurance products was randomised at the Iddir level to test their effectiveness. 
Our extension examines whether increases in insurance uptake are consistent with the author’s theory that financial constraints limit uptake. If true, one would expect increased drought insurance uptake among poorer smallholders. The study's findings have implications for policymakers and stakeholders working to improve the financial resilience of smallholder farmers in developing countries and increase smallholder investment in new technologies.
The design of the original papers’ novel insurance product is motivated by the findings of two previous studies, which it builds upon. 
The first study, by Casaburi and Willis (2018), studies delayed payments of the premium to induce insurance uptake when insurance is interlinked with a contract farming scheme. This prevents defaults on the premium payment commitments as premiums are deducted from the revenues paid after harvest (but contract enforcement issues remain because of the risk of side-selling).
The second study, by Dercon et al. (2014), investigates the effectiveness of marketing through informal local groups to boost insurance uptake. Additionally, they consider the impact of delaying insurance premiums on insurance uptake. Belissa et al. (2019) test both measures in several combinations to examine their effects on insurance updates and defaults. 
The findings of Belissa et al. (2019) share similarities with Casaburi and Willis (2018) outside a contract farming context. The study finds that the demand-increasing effect of the IOUs may be more significant for players with low savings or income, in line with Dercon et al. (2014). The result suggests that liquidity constraints impede the uptake of drought-based insurance. By building on and extending previous research, the study provides a more nuanced understanding of the factors that affect insurance uptake among smallholder farmers in developing countries.
Our heterogeneity analysis focuses on two household characteristics, household income and savings. The authors undertake limited heterogeneity analysis in the paper, comparing below and above median income and participants with and without savings. We take a more nuanced approach using machine learning to calculate heterogeneity across the income and savings spectrum. Specifically, we implement a Multi Arm Causal Forest model developed by Wager and Athey (2017) to estimate these effects across several treatments. This extension aims to determine whether the author’s theory that liquidity issues hamper drought-based insurance uptake among agricultural smallholders in Ethiopia is consistent with the results. 

(More details of results and conclusions needed.)

The paper is structured into six sections. The first section is the introduction, which overviews the study and its objectives. The second section is the literature review, which discusses the research on the topic and identifies the research gaps the study aims to address. The third section is the methodology, which describes the data sources, study design, and statistical techniques used to analyse the data. The fourth section is the results, which present the study findings. The fifth section, the extension, discusses the multi-arm causal forest approach used to estimate heterogeneous treatment effects. The sixth and final section is the conclusion, summarising the study's key findings and their implications for policy and future research.


\section{Literature Review}

\begin{itemize}

\item Summarize the literature relevant to the original study and the replication

\item Discuss any issues with the original study that have been raised in the literature

\end{itemize}


\section{Methodology}

\begin{itemize}

\item Describe the data and methods used in the original study

\item Explain the steps taken to replicate the original study, including any changes made to the methods or data

\item Discuss any challenges faced in replicating the original study

\end{itemize}

C1. Replication Methodology: In this subsection, we describe the methodology used to replicate the original study. We provide a detailed explanation of the data and methods used in the original study, including any necessary assumptions or model specifications. We also explain the steps taken to ensure that our replication accurately reproduces the original study's results.

The authors employed a multi-arm Randomized Control Trial (RCT) methodology to estimate the causal effects of their novel insurance products on index-based insurance uptake among smallholders. In contrast to traditional two-arm RCTs, a multi-arm RCT compares more than two intervention groups to a control group, in this case, five. Each intervention group receives a different treatment, and the primary objective is to identify the most effective treatment(s), with the control group serving as the baseline comparison. Compared to two-arm RCTs, multi-arm RCTs offer several benefits, including increased study efficiency, potential identification of multiple effective treatments, and decreased risk of false-negative results. However, multi-arm RCTs can be more challenging due to increased trial design, analysis, and interpretation complexity. As a result, careful planning and execution are necessary to ensure the comparability of intervention arms and the study's ability to detect meaningful differences between the groups.
The authors estimate causal effects for cross-sectional data via ordinary least squares (OLS). This method involves regressing the outcome variable on the treatment variable and any other relevant predictor variables. The coefficient for the treatment variable represents the average difference in the outcome variable between the treatment and control groups, controlling for any other relevant variables.
OLS is a widely used statistical technique often applied in an RCT to estimate the effect of an intervention on an outcome variable. OLS offers several advantages, including its ability to control for other factors that might influence the outcome, making it easier to communicate study results to a broader audience, and providing estimates of treatment effects that can be used to calculate the cost-effectiveness of the intervention.
However, OLS has some disadvantages that should be considered in an RCT. One major drawback is its assumption of a linear relationship between the outcome variable and explanatory variables. The results may be biased or inaccurate if this assumption is not met. OLS also does not account for potential confounding variables that were not included in the regression model, leading to biased estimates of treatment effects. Lastly, OLS requires a large sample size to provide reliable estimates of treatment effects, and if the sample size is too small, the results may be unreliable.


C2. Extension Methodology: In this subsection, we describe the methodology used for our extension analysis, which seeks to estimate heterogeneous treatment effects using a multi-arm causal forest approach. We provide an overview of the statistical methods employed, including any necessary assumptions or model specifications.

We apply a multi-arm causal forest model methodology to extend the original report’s findings to estimate the heterogeneous treatment effects. A multi-arm causal forest is a machine-learning algorithm that can estimate the causal effect of multiple treatments on an outcome variable in a randomised control trial (RCT) setting. It extends the Random Forest algorithm commonly used for prediction tasks.

The multi-arm causal forest model builds on the traditional Random Forest model by incorporating information about the treatment assignments in the RCT. The key idea of a causal forest model is to build causal trees, which are decision trees that partition the data based on the causal effect of a specific feature. These trees can then be aggregated to create a causal forest, which provides an estimate of the treatment effect. A multi-arm causal forest model broadens the base causal forest algorithm to model for multiple treatment groups compared to the control group.

We implement the multi-arm casual forest model Nie and Wager (2021) suggested. This approach extends the causal forest algorithm, a machine learning algorithm that estimates treatment effects by partitioning the data into subgroups based on observed covariates. The quasi-oracle approach extends the causal forest algorithm by using kernel weights to estimate the treatment effect for multiple treatment arms simultaneously.

The equation is given by:
$\tilde{\tau}(x) = \operatorname{argmin}{\tau} \left{ \sum{i=1}^n \alpha_i(x) \left(Y_i - \bar{m}^{(-i)}(X_i) - c(x) - \langle W_i - \hat{e}^{(-i)}(X_i), \tau(X_i) \rangle \right)^2 \right}$

In this equation, $\tilde{\tau}(x)$ represents the estimated conditional average treatment effect for the target sample $x$. The subscript $i$ refers to the $i$th observation in the sample, and $n$ represents the total number of observations. The observed outcomes are denoted by $Y_i$, and the observed covariates by $X_i$. The estimated propensity score is denoted by $\hat{e}(X_i)$, and is a vector-valued function that assigns a probability to each treatment arm, conditional on the observed covariates.

The weights $\alpha_i(x)$ reflect the contribution of each observation to the estimation of the treatment effect for the target sample $x$. The intercept term $c(x)$ is a nuisance parameter that captures any systematic bias in the treatment effect estimates that is not captured by the observed covariates or the estimated propensity score.

The term $\bar{m}^{(-i)}(X_i)$ represents the average outcome for the control group, which is estimated by excluding the $i$th observation from the sample. The notation $(-i)$ indicates that the $i$th observation is excluded from the calculation. Similarly, the term $\hat{e}^{(-i)}(X_i)$ represents the estimated propensity score for the control group, which is also estimated by excluding the $i$th observation from the sample.

The term $\langle W_i - \hat{e}^{(-i)}(X_i), \tau(X_i) \rangle$ represents the estimated treatment effect for each treatment arm, which is a linear combination of the estimated propensity score and the observed covariates. The notation $\langle \cdot, \cdot \rangle$ denotes the inner product of two vectors.

The optimisation problem seeks to find the value of $\tilde{\tau}(x)$ that minimises the sum of squared residuals, given the observed covariates, the estimated propensity score, and the weights $\alpha_i(x)$. The resulting value of $\tilde{\tau}(x)$ represents the estimated treatment effect for each treatment arm, conditional on the observed covariates for the target sample $x$.

However, the quasi-oracle approach has some weaknesses. The approach requires a large sample size for sufficient statistical power, especially when estimating treatment effects for rare subgroups or interactions. Secondly, the approach is computationally intensive and can be time-consuming to implement, especially when simultaneously estimating treatment effects for multiple outcomes. Additionally, the approach may suffer from overfitting and may be sensitive to the choice of hyperparameters. Lastly, the quasi-oracle approach assumes that the treatment assignment mechanism is ignorable, meaning that no unobserved confounding variables affect both the treatment assignment and the outcome. If this assumption is violated, the treatment effect estimates may be biased.

<point out that we have a small number of observations. Overfitting is a potential issues as we have a large number of covariates. We assume no confounders, so balancing must be correct otherwise we have bias.> 


C3. Estimating Heterogeneous Treatment Effects: In this subsection, we provide a detailed explanation of our approach to estimating heterogeneous treatment effects using the multi-arm causal forest method. This includes information on the choice of tuning parameters, model diagnostics, and methods used for inference.

Our approach to estimating heterogeneous treatment effects using the multi-arm causal forest method consists of several steps:

Data preparation: We first prepare the data by selecting relevant covariates and outcome variables, and by converting categorical variables to numeric ones. We also specify the reference level for the treatment variable.

Propensity score estimation: We estimate the propensity score, which is the probability of receiving treatment conditional on the covariates. This is done using logistic regression, where the treatment variable is the dependent variable and the covariates are the independent variables.

Causal forest estimation: We then estimate the causal forest using the multi-arm version of the method, where we include all treatment arms in the model. The causal forest is a collection of decision trees, where each tree predicts the outcome variable for a particular treatment arm, given the covariates and the propensity score.

Treatment effect estimation: Once the causal forest is estimated, we use it to estimate the heterogeneous treatment effects. This is done by calculating the difference in predicted outcomes between each treatment arm and the reference arm, for each individual. These differences are the estimated treatment effects.

C4. Sensitivity Analyses: In this subsection, we describe the sensitivity analyses conducted to assess the robustness of our results to potential model misspecification and data limitations. We also discuss any limitations or caveats to our approach and provide suggestions for future research.

We also perform a sensitivity analysis to assess the robustness of our results to different specifications of the causal forest model. This involves varying the parameters of the model, such as the number of trees and the minimum leaf size, and comparing the estimated treatment effects across different models.

C5. Challenges and Limitations: In this subsection, we discuss any challenges faced in replicating the original study, including any discrepancies or issues with the data or code. We also discuss the limitations of our replication and extension analysis and provide suggestions for improving future research.

When checking the dataset we obtained from the official resource, we found that the numbers of \textit{Iddirs} of three groups---IBI, IOU and IOU_C, are much larger than the results in the original paper, while the total number of \textit{Iddirs} and the numbers of observations of all groups are consistent. This issue indicates the fact that households in each \textit{Iddir} received different kinds of treatment, which is inconsistent with what the authors state in the paper. And the original paper does not explain whether/how they recategorise the households into new \textit{Iddirs}. We tried to contact the corresponding author, but he could not provide us a clear explanation in time because of some private reasons. So, due to this ambiguity, our randomisation does not work as well as that of the original study, and it leads to regression results that are different from those obtained by the authors.


\section{Results}

\begin{itemize}

\item Present the results of the replication study and compare them to the original results

\item Discuss any discrepancies between the two studies and their potential causes

\end{itemize}

<<<<<<< HEAD

The results of randomisation are shown in Table 1 and 2, from which we can see that the significance levels of much more coefficients increase compared to the original paper. It means that different treatment groups produce on average very different products and thus the treatment status may affect almost all important observables. Therefore, we cannot ignore the selection bias. We believe this is resulted from the data issue we show in the last section. However, we cannot correct it and the reliability of our study will be declined.
=======
This chapter aims to replicate the findings of Belissa et al. (2019) in their study on drought insurance uptake among smallholder farmers in Ethiopia. The original study uses a randomised controlled trial (RCT) to test the effectiveness of modified index-based insurance products, which aim to alleviate liquidity constraints and increase trust among smallholders. Our replication examines the key findings of the original study, including the impact of deferred IOU payment, marketing through local leaders, and harsher contract terms on insurance uptake and defaults. By replicating the study, we aim to verify the robustness of the original findings and contribute to the reproducibility and transparency of research in development economics.

\subsection{Data}

To begin our replication, we first verified the consistency of the randomisation process in our dataset with that reported by Belissa et al. (2019). The original paper states that randomisation occurred at the Iddir level, with 144 iddirs across the treatment and control arms. However, upon examination of the data, we found that the total number of iddirs across treatment arms was 226, with several Iddirs appearing in multiple arms. Only the Standard Insurance via Iddir Promotions seems unaffected. We confirmed that our replication code did not alter the data and obtained a second dataset from another source, which yielded the same result. Thus, we conclude that the replication data was systematically distorted before uploading. We have contacted the original author concerning the paper.

<dummy table/counts by iddir and obs>

Note that using a distorted dataset will affect our ability to replicate further material from the original paper. In particular, this will affect our calculation of heterogeneous treatment effects in the extension due to the distortion of the randomisation arm, which relies on randomisation for unconfoundedness.

\subsection{Randomisation}

To verify whether randomisation was successful and that treatment is not confounded by other variables balancing tests are required to ensure no significant differences between groups before intervention. If groups differ significantly, it may bias the results making it difficult to mark causal inference.

We then assess the balancing of the randomisation process. The original paper used this to verify the success of the randomisation process for causal inference. We match the author’s approach and regress a battery of socio-economic, production and savings variables on the treatment groups. We do not include the control group, the “Standard Index Insurance” dummy, which is therefore reflected in the constant.

Comparing the constants of our balancing test to Table 1 in the original paper, we attempt to trace the impact of the data distortion. Constants for Age, Sex, Education, Family Size, Monthly Income, Drought Severity and Previous Insurance are unaffected. The marriage dummy is significantly higher at 0.95 compared to 0.90 in the original paper. Point estimates for each independent variable adhere closely to those presented in the original paper. However, they do not match exactly in almost all cases. This would suggest that distortions in the dataset are relatively small.
>>>>>>> 624fc16b69c34032a124f3e6a6582b7e4d9bc088

Table 1
<Drought variable is too high. Coding error on our part. Need to fix. Must be if any Yes=1>

We test whether the treatments’ coefficients are equal via the Wald test. In general, the results are highly significant except for the education variable. High significant levels would normally lead us to conclude that coefficients are unequal. However, in the context of data distortions noted in the dataset between randomisation and clusters, particularly as we are required to clusters robust errors by iddir, we cannot discount the possibility that our results are distorted.

Distortions of the constants in Table 2 remain small but are more frequent. Only the constant for Wheat (5.09) matches the original paper. All other constants align closely with the original paper but differ somewhat. The increased frequency of departures from the original paper may not represent any distortion pattern, but this data contains more variance, and therefore distortions are more visible.

Table 2
<savings variable is too high. May be a coding error on our part. Need to fix. Must be if any Yes=1>

Wald tests for joint significance between treatment arms in production variables are again extremely significant. These results are substantially more significant than in the original paper.  The high significance level likely represents the earlier distortions noted in the dataset between randomisation and clusters, particularly as Iddir clusters robust errors. 
As noted previously regarding Table 1. The results of our Wald test are highly significant. Usually, this would lead us to conclude that the coefficients are significantly different. However, we are reluctant to place faith in the results in light of our data issues.

\subsection{Uptake Rates}

Figure 2 illustrates the insurance uptake rates across various treatment arms. The IOU product's delayed payment option shows a substantial increase in uptake compared to standard insurance, jumping from 8% to 24%. The combination of IOU and promotion through Iddir outperforms all other treatments, with uptake rates reaching approximately 43%. These results are consistent with those reported in the original paper, except for Group 6, which received the most comprehensive intervention package, including IOU, promotion by Iddir leaders, and a binding contract. In our study, the uptake rate of this group was slightly lower than in the original experiment, specifically 27% compared to 32%. However, upon further examination of the data, we discovered that around 5% of households in this group took up an IOU via Iddir without signing a contract, which explains the discrepancy between our findings and those of the authors. Consequently, we have adopted the authors' calculation method in our subsequent research.

<Fig. 2. Uptake rates across IOU treatments, 95% CI clustered at Iddir level.>



\section{Extension}

\begin{itemize}

\item Describe any additional analyses or tests performed using the replicated data

\item Discuss the implications of the extended analysis for the original findings and the literature

\end{itemize}


\section{Conclusion}

\begin{itemize}

\item Summarize the findings of the replication and extension studies

\item Discuss the implications of the replication for the original study and the literature

\item Recommend any changes to the original methods or data for future research

\end{itemize}

In this study, we replicate the main results obtained by Belissa et al. (2019) and use the causal forests developed by Waiger and Athey (2017) to conduct heterogeneity analysis, trying to have a closer look at the heterogeneous effects of the multi-arm treatments of the insurance design on households with different socio-economic and production characteristics.

The replication task does not fully reproduce the results obtained by the authors. We download the dataset from the official website and find an obvious data issue that leads to discrepancies in the results---the numbers of \textit{Iddirs} of three treatment groups are much higher than those shown in the original paper. This indicates that some \textit{Iddirs} received different types of policy impacts, which is different from what the authors state in the paper. With inability to solve this issue, we show that our randomisation does not work as well as the original study. However, we still obtain very similar results in the subsequent analysis, including the uptake rates of different types of insurance designs and the effects of the insurance designs gained from the regressions. We can still conclude that delaying weather insurance payment (IOU) increases uptake and promoting weather insurance via \textit{Iddir} leaders increases uptake of IOU. And we also find a negative role of binding contracts.

We then use the multi-arm causal forest to extend the heterogeneity analysis.


## Document Styling Guidelines
\begin{itemize}
\item Do not use an "Introduction" heading. Begin your introductory material
before the first section heading.

\item Avoid style markup (except sparingly for emphasis).

\item Avoid using explicit vertical or horizontal space.

\item Captions are short and go below figures but above tables.

\item The tablenotes or figurenotes environments may be used below tables
or figures, respectively, as demonstrated below.

\item If you have difficulties with the mathtime package, adjust the package
options appropriately for your platform. If you can't get it to work, just
remove the package or see our technical support document online (please
refer to the author instructions).

\item If you are using an appendix, it goes last, after the bibliography.
Use regular section headings to make the appendix headings.

\item If you are not using an appendix, you may delete the appendix command
and sample appendix section heading.

\item Either the natbib package or the harvard package may be used with bibtex.
To include one of these packages, uncomment the appropriate usepackage command
above. Note: you can't use both packages at once or compile-time errors will result.

\end{itemize}

##
\section{First Section in Body}

Sample figure:

\begin{figure}
Figure here.

\caption{Caption for figure below.}
\begin{figurenotes}
Figure notes without optional leadin.
\end{figurenotes}
\begin{figurenotes}[Source]
Figure notes with optional leadin (Source, in this case).
\end{figurenotes}
\end{figure}

Sample table:

\begin{table}
\caption{Caption for table above.}

\begin{tabular}{lll}
& Heading 1 & Heading 2 \\
Row 1 & 1 & 2 \\
Row 2 & 3 & 4%
\end{tabular}
\begin{tablenotes}
Table notes environment without optional leadin.
\end{tablenotes}
\begin{tablenotes}[Source]
Table notes environment with optional leadin (Source, in this case).
\end{tablenotes}
\end{table}

References here (manual or bibTeX). If you are using bibTeX, add your bib file
name in place of BibFile in the bibliography command.
% Remove or comment out the next two lines if you are not using bibtex.
\bibliographystyle{aea}
\bibliography{references}

% The appendix command is issued once, prior to all appendices, if any.
\appendix

\section{Mathematical Appendix}
